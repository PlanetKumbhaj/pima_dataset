{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PlanetKumbhaj/pima_dataset/blob/main/ML_pima_Indian_diabetes_dataset_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7saPblLSvROr"
      },
      "source": [
        "**importing the library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvYoUwmTvsy9"
      },
      "outputs": [],
      "source": [
        "from logging import warning\n",
        "import  numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZaeQe87Shd3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "glVFij73hd9N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JPEtQ4sgheOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XN6IBePxBFm"
      },
      "source": [
        "**Data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEiTzjXNxag6"
      },
      "outputs": [],
      "source": [
        "pidd = pd.read_csv('/content/dataset of PIDD.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDxrgWplyWwH"
      },
      "source": [
        "**Checking the first five value of the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhBnNLi7yBIK"
      },
      "outputs": [],
      "source": [
        "pidd.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5SClj3My_FO"
      },
      "source": [
        "**Finding the no of Rows and Columns in the given dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xilLWWmByTd7"
      },
      "outputs": [],
      "source": [
        "pidd.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdtSeqLBzY9Q"
      },
      "source": [
        "**Describing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqUqDZxozN11"
      },
      "outputs": [],
      "source": [
        "pidd.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Li4USgZz1K6"
      },
      "source": [
        "**information of the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_UrlM-7zniS"
      },
      "outputs": [],
      "source": [
        "pidd.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB--jImb1V6p"
      },
      "source": [
        "**Finding the missing value in the given dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVgLvRyD1RyL"
      },
      "outputs": [],
      "source": [
        "pidd['Pregnancies']=pidd['Pregnancies'].replace(0, np.nan)\n",
        "pidd['Glucose']=pidd['Glucose'].replace(0, np.nan)\n",
        "pidd['BloodPressure']=pidd['BloodPressure'].replace(0, np.nan)\n",
        "pidd['SkinThickness']=pidd['SkinThickness'].replace(0, np.nan)\n",
        "pidd['Insulin']=pidd['Insulin'].replace(0, np.nan)\n",
        "pidd['BMI']=pidd['BMI'].replace(0, np.nan)\n",
        "pidd['DiabetesPedigreeFunction']=pidd['DiabetesPedigreeFunction'].replace(0, np.nan)\n",
        "pidd['Age']=pidd['Age'].replace(0, np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfHxD9hI29gt"
      },
      "outputs": [],
      "source": [
        "pidd.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FlTP68D7dL5"
      },
      "outputs": [],
      "source": [
        "pidd['Outcome'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAEU4Uoz-NFl"
      },
      "outputs": [],
      "source": [
        "pidd.groupby('Outcome').mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYZ2SWsK-Z7a"
      },
      "outputs": [],
      "source": [
        "pidd.BMI = pidd.BMI.fillna(pidd.BMI.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJylPSKC_9D_"
      },
      "outputs": [],
      "source": [
        "pidd.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QzTrk86AE8z"
      },
      "outputs": [],
      "source": [
        "pidd.groupby('BMI').mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZm6Rl2vAQnX"
      },
      "outputs": [],
      "source": [
        "pidd['Pregnancies'].value_counts().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s2Xv0BQAteW"
      },
      "outputs": [],
      "source": [
        "pidd.groupby('Pregnancies').mean().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pidd['SkinThickness'].value_counts().sum()"
      ],
      "metadata": {
        "id": "b3a-AfrozQ9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wA5UkTOIV8q"
      },
      "outputs": [],
      "source": [
        "pidd.groupby('SkinThickness').mean().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRVFEHZ2JLz5"
      },
      "outputs": [],
      "source": [
        "pidd.Pregnancies = pidd.Pregnancies.fillna(pidd.Pregnancies.mean())\n",
        "pidd.Glucose = pidd.Glucose.fillna(pidd.Glucose.mean())\n",
        "pidd.BloodPressure  = pidd.BloodPressure .fillna(pidd.BloodPressure .mean())\n",
        "pidd.Insulin = pidd.Insulin.fillna(pidd.Insulin.mean())\n",
        "pidd.SkinThickness = pidd.SkinThickness.fillna(pidd.SkinThickness.median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9Rj1bg-JPx-"
      },
      "outputs": [],
      "source": [
        "pidd.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNA73rEzOKcB"
      },
      "source": [
        "**Data visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuSUWx1XLSDS"
      },
      "outputs": [],
      "source": [
        "sns.countplot('Outcome',data=pidd)\n",
        "pidd['Outcome'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENqbTmCYQW62"
      },
      "outputs": [],
      "source": [
        "pidd.hist(bins=10,figsize=(10,10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J57cIyBfgAcW"
      },
      "source": [
        "**ploting the scatter matrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOZdxaLif7qX"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(pidd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37JiybSoSl1E"
      },
      "source": [
        "**Spliting the data into x and y** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCjJ9qAZOe3-"
      },
      "outputs": [],
      "source": [
        "y= pidd['Outcome']\n",
        "X=pidd.drop('Outcome',axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuP0sPZGSs52"
      },
      "source": [
        "**Train  the spliting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dsdtu6YLe_O"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.3,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8jx3iUwRNOF"
      },
      "outputs": [],
      "source": [
        "X_train.shape,y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YL3hIUtVajB"
      },
      "outputs": [],
      "source": [
        "X_test.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvBeCEfpWVn2"
      },
      "source": [
        "**Classification Algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fR_I_0tCpU5"
      },
      "source": [
        "**K Nearest Neighbours**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6PXHVCCCzOU"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR99M9MFgkNx"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "\n",
        "  \n",
        "# train the model on train set\n",
        "knn.fit(X_train, y_train.ravel())\n",
        "  \n",
        "\n",
        "pred = knn.predict(X_test)\n",
        "  \n",
        "# print classification report\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cxLmKzBH5T9"
      },
      "outputs": [],
      "source": [
        "print(\"\\n F1:\\n\",f1_score(y_test,pred))\n",
        "print(\"\\n Precision score is:\\n\",precision_score(y_test,pred))\n",
        "print(\"\\n Recall score is:\\n\",recall_score(y_test,pred))\n",
        "print(\"\\n Confusion Matrix:\\n\")\n",
        "sns.histplot(confusion_matrix(y_test,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1QqWMI_Cqm0"
      },
      "source": [
        "**Suppor vector machine model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uugIIiP-AfPg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tPJPT33c9Uo"
      },
      "outputs": [],
      "source": [
        "\n",
        "svm = SVC(kernel= 'linear', random_state=1, C=0.1)\n",
        "\n",
        "  \n",
        "# train the model on train set\n",
        "svm.fit(X_train, y_train.ravel())\n",
        "  \n",
        "pred = svm.predict(X_test)\n",
        "  \n",
        "# print classification report\n",
        "print(classification_report(y_test, pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cDZrPU2j2D3"
      },
      "outputs": [],
      "source": [
        "print(\"\\n F1:\\n\",f1_score(y_test,pred))\n",
        "print(\"\\n Precision score is:\\n\",precision_score(y_test,pred))\n",
        "print(\"\\n Recall score is:\\n\",recall_score(y_test,pred))\n",
        "print(\"\\n Confusion Matrix:\\n\")\n",
        "sns.histplot(confusion_matrix(y_test,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY8kjlDMiyka"
      },
      "source": [
        "**Logistic Regression classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toas3oqZ0AF-"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHDeg_d7cy3y"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression()\n",
        "  \n",
        "# train the model on train set\n",
        "lr.fit(X_train, y_train.ravel())\n",
        "  \n",
        "pred = lr.predict(X_test)\n",
        "  \n",
        "# print classification report\n",
        "print(classification_report(y_test, pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-cO31lJnbAs"
      },
      "outputs": [],
      "source": [
        "print(\"\\n F1:\\n\",f1_score(y_test,pred))\n",
        "print(\"\\n Precision score is:\\n\",precision_score(y_test,pred))\n",
        "print(\"\\n Recall score is:\\n\",recall_score(y_test,pred))\n",
        "print(\"\\n Confusi_matrix(y_test,lr_pred))on Matrix:\\n\")\n",
        "sns.histplot(confusion_matrix(y_test,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWTW7RZIrx9R"
      },
      "source": [
        "**Decision Tree classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVOGJ-1-nii0"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVLMo-PKxi0b"
      },
      "outputs": [],
      "source": [
        "knn= DecisionTreeClassifier()\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "pred = knn.predict(X_test)\n",
        "  \n",
        "# print classification report\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOGErxztyafi"
      },
      "outputs": [],
      "source": [
        "print(\"\\n F1:\\n\",f1_score(y_test,pred))\n",
        "print(\"\\n Precision score is:\\n\",precision_score(y_test,pred))\n",
        "print(\"\\n Recall score is:\\n\",recall_score(y_test,pred))\n",
        "print(\"\\n Confusion Matrix:\\n\")\n",
        "sns.histplot(confusion_matrix(y_test,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwNgAJrL4crO"
      },
      "source": [
        "**Random Forest**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKP9JVk50gUZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vximZGkS4nTw"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "  \n",
        "pred = rf.predict(X_test)\n",
        "  \n",
        "# print classification report\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biogtuOb6pp9"
      },
      "outputs": [],
      "source": [
        "print(\"\\n F1:\\n\",f1_score(y_test,pred))\n",
        "print(\"\\n Precision score is:\\n\",precision_score(y_test,pred))\n",
        "print(\"\\n Recall score is:\\n\",recall_score(y_test,pred))\n",
        "print(\"\\n Confusion Matrix:\\n\")\n",
        "sns.histplot(confusion_matrix(y_test,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2082mYJ677I"
      },
      "source": [
        "**Gaussian Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZLHMzGb6zoy"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IL6TsHz8AVO"
      },
      "outputs": [],
      "source": [
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "  \n",
        "pred = nb.predict(X_test)\n",
        "  \n",
        "# print classification report\n",
        "print(classification_report(y_test, pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE1Wo-pG9mG6"
      },
      "outputs": [],
      "source": [
        "print(\"\\n F1:\\n\",f1_score(y_test,pred))\n",
        "print(\"\\n Precision score is:\\n\",precision_score(y_test,pred))\n",
        "print(\"\\n Recall score is:\\n\",recall_score(y_test,pred))\n",
        "print(\"\\n Confusion Matrix:\\n\")\n",
        "sns.histplot(confusion_matrix(y_test,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo_FB0gOxhhV"
      },
      "source": [
        "**AdaBoost classifiction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUXZQ3Afxg_p"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier \n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHjFyE749u9Y"
      },
      "outputs": [],
      "source": [
        "ada = AdaBoostClassifier()\n",
        "\n",
        "ada.fit(X_train, y_train)\n",
        "  \n",
        "pred = ada.predict(X_test)\n",
        "  \n",
        "# print classification report\n",
        "print(classification_report(y_test, pred))\n",
        "acc = accuracy_score(y_test, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8yp4smV18VX"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy Result: %.2f%%\\n\"%(acc*100))\n",
        "print(\"\\n F1:\\n\",f1_score(y_test,pred))\n",
        "print(\"\\n Precision score is:\\n\",precision_score(y_test,pred))\n",
        "print(\"\\n Recall score is:\\n\",recall_score(y_test,pred))\n",
        "print(\"\\n Confusion Matrix:\\n\")\n",
        "sns.histplot(confusion_matrix(y_test,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj4uCunGwYVY"
      },
      "source": [
        "**SMOTE(Synthetic Minority Oversampling Technique)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5I3a8xyN3nO"
      },
      "outputs": [],
      "source": [
        "print(\"Data before using smote, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Data before using smote, counts of label '0': {} \\n\".format(sum(y_train == 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o21rbyYdUfyy"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()\n",
        "X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrqiLF_gQErO"
      },
      "outputs": [],
      "source": [
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj8EosIrU3_W"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X_train_res, y_train_res)\n",
        "pred = knn.predict(X_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ACCURECY OF DATA SET**"
      ],
      "metadata": {
        "id": "AcWr_K1rymDn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAWoAuDaWHq2"
      },
      "outputs": [],
      "source": [
        "acc = accuracy_score(y_test, pred)\n",
        "results_all = precision_recall_fscore_support(y_test, pred, average='macro', zero_division=1)\n",
        "results_class = precision_recall_fscore_support(y_test, pred, average=None, zero_division=1)\n",
        "metric_columns = ['Precision','Recall', 'F1-Score','S']\n",
        "all_df = pd.concat([pd.DataFrame(list(results_class)).T,pd.DataFrame(list(results_all)).T])\n",
        "all_df.columns = metric_columns\n",
        "\n",
        "def metrics_plot(df,metric):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    ax = sns.barplot(data=df, x=df.index, y=metric, palette = \"Blues_d\")\n",
        "    # Bar Labels\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(\"%.1f%%\" % (100*p.get_height()), (p.get_x() + p.get_width() / 2., abs(p.get_height())),\n",
        "        ha='center', va='bottom', color='black', xytext=(-3, 5),rotation = 'horizontal',textcoords='offset points')\n",
        "    sns.despine(top=True, right=True, left=True, bottom=False)\n",
        "    ax.set_xlabel('Class',fontsize = 14)\n",
        "    ax.set_ylabel(metric,fontsize = 14)\n",
        "    ax.set(yticklabels=[])\n",
        "    ax.axes.get_yaxis().set_visible(False) \n",
        "    plt.title(metric+ ' Results per Class', fontsize = 14);\n",
        "\n",
        "metrics_plot(all_df, 'Precision')       # Results by Class\n",
        "metrics_plot(all_df, 'Recall')          # Results by Class\n",
        "metrics_plot(all_df, 'F1-Score')         # Results by Class\n",
        "print('----------------- Overall Results -----------------')\n",
        "print('Accuracy Result: %.2f%%'%(acc*100))                   # Accuracy of the whole Dataset\n",
        "print('Precision Result: %.2f%%'%(all_df.iloc[2,0]*100))     # Precision of the whole Dataset\n",
        "print('Recall Result: %.2f%%'%(all_df.iloc[2,1]*100))        # Recall of the whole Dataset\n",
        "print('F1-Score Result: %.2f%%'%(all_df.iloc[2,2]*100))      # F1-Score of the whole Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ky3Azg-X4lrw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}